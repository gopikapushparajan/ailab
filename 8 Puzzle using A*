import heapq

class PuzzleState:
    def __init__(self, board, parent, move, depth, cost):
        self.board = board  # The current state of the puzzle as a tuple
        self.parent = parent  # The parent PuzzleState
        self.move = move  # The move that led to this state
        self.depth = depth  # g(n): cost from start to this state
        self.cost = cost  # f(n) = g(n) + h(n)

    def __lt__(self, other):
        return self.cost < other.cost

def manhattan_distance(board, goal):
    """Calculates the Manhattan distance heuristic."""
    distance = 0
    for i in range(1, 9):  # Iterate through tiles 1 to 8
        x1, y1 = divmod(board.index(i), 3)  # Current position of tile i
        x2, y2 = divmod(goal.index(i), 3)  # Goal position of tile i
        distance += abs(x1 - x2) + abs(y1 - y2)
    return distance

def get_blank_position(board):
    """Finds the position (row, col) of the blank tile (0)."""
    index = board.index(0)
    return divmod(index, 3)

def get_possible_moves(board):
    """Generates possible moves for the blank tile."""
    row, col = get_blank_position(board)
    moves = []
    # Up
    if row > 0:
        moves.append((-1, 0))
    # Down
    if row < 2:
        moves.append((1, 0))
    # Left
    if col > 0:
        moves.append((0, -1))
    # Right
    if col < 2:
        moves.append((0, 1))
    return moves

def apply_move(board, move):
    """Applies a move to the board and returns the new board state."""
    new_board = list(board)
    blank_index = new_board.index(0)
    blank_row, blank_col = divmod(blank_index, 3)

    dr, dc = move
    new_blank_row, new_blank_col = blank_row + dr, blank_col + dc
    new_blank_index = new_blank_row * 3 + new_blank_col

    new_board[blank_index], new_board[new_blank_index] = \
        new_board[new_blank_index], new_board[blank_index]
    return tuple(new_board)

def solve_8_puzzle_astar(initial_state, goal_state):
    """Solves the 8-puzzle problem using A* search."""
    explored = set()
    priority_queue = []

    initial_h_cost = manhattan_distance(initial_state, goal_state)
    initial_puzzle_state = PuzzleState(initial_state, None, None, 0, initial_h_cost)
    heapq.heappush(priority_queue, initial_puzzle_state)

    while priority_queue:
        current_state = heapq.heappop(priority_queue)

        if current_state.board == goal_state:
            return current_state  # Solution found

        if current_state.board in explored:
            continue
        explored.add(current_state.board)

        for move_delta in get_possible_moves(current_state.board):
            new_board = apply_move(current_state.board, move_delta)

            if new_board not in explored:
                new_depth = current_state.depth + 1
                new_h_cost = manhattan_distance(new_board, goal_state)
                new_total_cost = new_depth + new_h_cost
                new_puzzle_state = PuzzleState(new_board, current_state, move_delta, new_depth, new_total_cost)
                heapq.heappush(priority_queue, new_puzzle_state)

    return None  # No solution found

def print_solution(goal_node):
    """Prints the path from the initial state to the goal state."""
    path = []
    current = goal_node
    while current:
        path.append(current)
        current = current.parent
    path.reverse()

    for i, state in enumerate(path):
        print(f"Step {i}: Move {state.move if state.move else 'Start'}")
        for r in range(3):
            print(state.board[r*3 : (r+1)*3])
        print("-" * 10)

# Example Usage:
if __name__ == "__main__":
    initial_board = (1, 2, 3, 4, 0, 6, 7, 5, 8)  # 0 represents the blank space
    goal_board = (1, 2, 3, 4, 5, 6, 7, 8, 0)

    print("Solving 8-Puzzle using A* algorithm...")
    solution_node = solve_8_puzzle_astar(initial_board, goal_board)

    if solution_node:
        print("Solution found!")
        print_solution(solution_node)
    else:
        print("No solution found for this initial state.")
